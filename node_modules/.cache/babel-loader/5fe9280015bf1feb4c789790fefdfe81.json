{"ast":null,"code":"import * as faceapi from \"face-api.js\"; // Load models and weights\n\nexport async function loadModels() {\n  const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n  await faceapi.loadTinyFaceDetectorModel(MODEL_URL);\n  await faceapi.loadFaceLandmarkTinyModel(MODEL_URL);\n  await faceapi.loadFaceRecognitionModel(MODEL_URL);\n}\nexport async function getFullFaceDescription(blob) {\n  let inputSize = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 512;\n  // tiny_face_detector options\n  let scoreThreshold = 0.5;\n  const OPTION = new faceapi.TinyFaceDetectorOptions({\n    inputSize,\n    scoreThreshold\n  });\n  const useTinyModel = true; // fetch image to api\n\n  let img = await faceapi.fetchImage(blob); // detect all faces and generate full description from image\n  // including landmark and descriptor of each face\n\n  let fullDesc = await faceapi.detectAllFaces(img, OPTION).withFaceLandmarks(useTinyModel).withFaceDescriptors();\n  return fullDesc;\n}\nconst maxDescriptorDistance = 0.5;\nexport const createMatcher = async faceProfiles => {\n  let members = Object.keys(faceProfiles);\n  let labeledDescriptors = members.map(member => {\n    let label = faceProfiles[member].email;\n    let descriptors = [];\n    let descriptor = new Float32Array(faceProfiles[member].descriptors);\n    descriptors.push(descriptor);\n    return new faceapi.LabeledFaceDescriptors(label, descriptors);\n  });\n  let faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, maxDescriptorDistance);\n  return faceMatcher;\n};","map":{"version":3,"sources":["/Users/yolo/Documents/dev/js/faceid/src/api/face.jsx"],"names":["faceapi","loadModels","MODEL_URL","process","env","PUBLIC_URL","loadTinyFaceDetectorModel","loadFaceLandmarkTinyModel","loadFaceRecognitionModel","getFullFaceDescription","blob","inputSize","scoreThreshold","OPTION","TinyFaceDetectorOptions","useTinyModel","img","fetchImage","fullDesc","detectAllFaces","withFaceLandmarks","withFaceDescriptors","maxDescriptorDistance","createMatcher","faceProfiles","members","Object","keys","labeledDescriptors","map","member","label","email","descriptors","descriptor","Float32Array","push","LabeledFaceDescriptors","faceMatcher","FaceMatcher"],"mappings":"AAAA,OAAO,KAAKA,OAAZ,MAAyB,aAAzB,C,CAEA;;AACA,OAAO,eAAeC,UAAf,GAA4B;AACjC,QAAMC,SAAS,GAAGC,OAAO,CAACC,GAAR,CAAYC,UAAZ,GAAyB,SAA3C;AACA,QAAML,OAAO,CAACM,yBAAR,CAAkCJ,SAAlC,CAAN;AACA,QAAMF,OAAO,CAACO,yBAAR,CAAkCL,SAAlC,CAAN;AACA,QAAMF,OAAO,CAACQ,wBAAR,CAAiCN,SAAjC,CAAN;AACD;AAED,OAAO,eAAeO,sBAAf,CAAsCC,IAAtC,EAA6D;AAAA,MAAjBC,SAAiB,uEAAL,GAAK;AAClE;AACA,MAAIC,cAAc,GAAG,GAArB;AACA,QAAMC,MAAM,GAAG,IAAIb,OAAO,CAACc,uBAAZ,CAAoC;AACjDH,IAAAA,SADiD;AAEjDC,IAAAA;AAFiD,GAApC,CAAf;AAIA,QAAMG,YAAY,GAAG,IAArB,CAPkE,CASlE;;AACA,MAAIC,GAAG,GAAG,MAAMhB,OAAO,CAACiB,UAAR,CAAmBP,IAAnB,CAAhB,CAVkE,CAYlE;AACA;;AACA,MAAIQ,QAAQ,GAAG,MAAMlB,OAAO,CACzBmB,cADkB,CACHH,GADG,EACEH,MADF,EAElBO,iBAFkB,CAEAL,YAFA,EAGlBM,mBAHkB,EAArB;AAIA,SAAOH,QAAP;AACD;AAED,MAAMI,qBAAqB,GAAG,GAA9B;AAEA,OAAO,MAAMC,aAAa,GAAG,MAAOC,YAAP,IAAwB;AACnD,MAAIC,OAAO,GAAGC,MAAM,CAACC,IAAP,CAAYH,YAAZ,CAAd;AACA,MAAII,kBAAkB,GAAGH,OAAO,CAACI,GAAR,CAAaC,MAAD,IAAY;AAC/C,QAAIC,KAAK,GAAGP,YAAY,CAACM,MAAD,CAAZ,CAAqBE,KAAjC;AACA,QAAIC,WAAW,GAAG,EAAlB;AACA,QAAIC,UAAU,GAAG,IAAIC,YAAJ,CAAiBX,YAAY,CAACM,MAAD,CAAZ,CAAqBG,WAAtC,CAAjB;AACAA,IAAAA,WAAW,CAACG,IAAZ,CAAiBF,UAAjB;AACA,WAAO,IAAIlC,OAAO,CAACqC,sBAAZ,CAAmCN,KAAnC,EAA0CE,WAA1C,CAAP;AACD,GANwB,CAAzB;AAQA,MAAIK,WAAW,GAAG,IAAItC,OAAO,CAACuC,WAAZ,CAChBX,kBADgB,EAEhBN,qBAFgB,CAAlB;AAIA,SAAOgB,WAAP;AACD,CAfM","sourcesContent":["import * as faceapi from \"face-api.js\";\n\n// Load models and weights\nexport async function loadModels() {\n  const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n  await faceapi.loadTinyFaceDetectorModel(MODEL_URL);\n  await faceapi.loadFaceLandmarkTinyModel(MODEL_URL);\n  await faceapi.loadFaceRecognitionModel(MODEL_URL);\n}\n\nexport async function getFullFaceDescription(blob, inputSize = 512) {\n  // tiny_face_detector options\n  let scoreThreshold = 0.5;\n  const OPTION = new faceapi.TinyFaceDetectorOptions({\n    inputSize,\n    scoreThreshold,\n  });\n  const useTinyModel = true;\n\n  // fetch image to api\n  let img = await faceapi.fetchImage(blob);\n\n  // detect all faces and generate full description from image\n  // including landmark and descriptor of each face\n  let fullDesc = await faceapi\n    .detectAllFaces(img, OPTION)\n    .withFaceLandmarks(useTinyModel)\n    .withFaceDescriptors();\n  return fullDesc;\n}\n\nconst maxDescriptorDistance = 0.5;\n\nexport const createMatcher = async (faceProfiles) => {\n  let members = Object.keys(faceProfiles);\n  let labeledDescriptors = members.map((member) => {\n    let label = faceProfiles[member].email;\n    let descriptors = [];\n    let descriptor = new Float32Array(faceProfiles[member].descriptors);\n    descriptors.push(descriptor);\n    return new faceapi.LabeledFaceDescriptors(label, descriptors);\n  });\n\n  let faceMatcher = new faceapi.FaceMatcher(\n    labeledDescriptors,\n    maxDescriptorDistance\n  );\n  return faceMatcher;\n};\n"]},"metadata":{},"sourceType":"module"}